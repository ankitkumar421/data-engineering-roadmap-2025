<p align="center">
  <img src="https://img.shields.io/badge/Progress-Documenting-blue?style=flat-square" />
  <img src="https://img.shields.io/badge/Data%20Engineering-2025-green?style=flat-square" />
  <img src="https://img.shields.io/badge/Python-3.11-blue?logo=python&logoColor=white&color=blue" />
  <img src="https://img.shields.io/badge/LinkedIn-Connect-blue?logo=linkedin&logoColor=white&color=0077B5" />
</p>

# 🚀 Data Engineering Roadmap 2025

Welcome to my step-by-step **Data Engineering learning journey for 2025**!  
I'm learning week by week, pushing code and sharing my progress publicly on [LinkedIn](https://linkedin.com/in/ankitofficial421).

---

## ✅ Progress Checklist

- **Week 1: Python ETL Foundations**
  - 🐼 Pandas Basics
  - 🔄 ETL Pipeline → SQLite
  - 📊 Query SQLite
  - 📈 Auto Reports (Excel/CSV)
  - ⏰ Task Scheduler Automation

- **Week 2: PySpark Foundations**
  - ⚡ Spark Setup & Session
  - 📊 RDDs vs DataFrames
  - 🔨 Transformations & Actions
  - 📝 Spark SQL Queries
  - 🔗 Joins & Aggregations
  - 🪟 Window Functions

- **Week 3: Advanced PySpark** *(in progress!)*
  - 🛠️ UDFs
  - 🗂️ Partitioning & Bucketing
  - 🚀 Performance Optimizations
  - 🎯 Caching & Persistence
  - 📁 File Formats (Parquet, ORC, JSON)
  - 📦 Mini Project: Optimized ETL pipeline

---

## 📂 Repository Structure

```
data-engineering-roadmap-2025/
│
├── data/                # Sample datasets (sales.csv, customers.csv, etc.)
├── week1/               # Week 1 notebooks & scripts
├── week2/               # Week 2 notebooks & scripts
├── requirements.txt     # Python dependencies
└── README.md            # This file
```

---

## 🛠️ Tech Stack

- **Python 3.11** → Data pipelines
- **Pandas** → Data wrangling
- **SQLite** → Lightweight DB
- **PySpark** → Distributed big data processing
- **Docker** → Environment setup & reproducibility

---

## 🌍 Learning in Public

I'm documenting my journey with recap posts after each day/week.  
👉 **Follow my updates on [LinkedIn](https://linkedin.com/in/ankitofficial421)**

---

## 🔜 Next Steps

- Continue with Week 3: Advanced PySpark
- Explore **Cloud Data Engineering** (Azure/GCP)
- Build real-world mini projects & ETL pipelines

---

✨ *This repo is my public accountability tracker and a resource for anyone starting in Data Engineering. Happy Learning!* ✨
