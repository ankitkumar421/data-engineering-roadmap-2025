This repository documents my step-by-step Data Engineering learning journey for 2025.
I’m learning week by week, pushing code here, and sharing my progress publicly on LinkedIn.

✅ Progress Checklist

 Week 1: Python ETL Foundations

 Pandas Basics

 ETL Pipeline → SQLite

 Query SQLite

 Auto Reports (Excel/CSV)

 Task Scheduler Automation

 Week 2: PySpark Foundations

 Spark Setup & Session

 RDDs vs DataFrames

 Transformations & Actions

 Spark SQL Queries

 Joins & Aggregations

 Window Functions

 Week 3: Advanced PySpark

 UDFs (User Defined Functions)

 Partitioning & Bucketing

 Performance Optimizations

 Caching & Persistence

 File Formats (Parquet, ORC, JSON)

 Mini Project: Optimized ETL pipeline

📂 Repository Structure
data-engineering-roadmap-2025/
│
├── data/                   # Sample datasets (sales.csv, customers.csv, etc.)
├── week1/                  # Week 1 notebooks & scripts
├── week2/                  # Week 2 notebooks & scripts
├── requirements.txt        # Dependencies
└── README.md               # This file

🛠️ Tech Stack

Python 3.11 → Data pipelines

Pandas → Data wrangling

SQLite → Lightweight DB

PySpark → Distributed big data processing

Docker → Environment setup & reproducibility

🌍 Learning in Public

I’m documenting my journey on LinkedIn after each day/week.
👉 Follow my updates here: LinkedIn

🔜 Next Steps

Continue with Week 3: Advanced PySpark

Explore Cloud Data Engineering (Azure/GCP)

Build real-world mini projects & pipelines

✨ This repo is my public accountability tracker and a resource for anyone starting in Data Engineering.