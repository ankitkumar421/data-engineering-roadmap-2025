{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6138255f-df7d-4295-ac5c-b0789458905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, isnan, when\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"/home/jovyan/work/week5/data_quality.log\",\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f0f9c1-437d-49b1-8281-a380d569265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Week5_Data_Quality\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693f0ff2-05f6-4890-a1b5-0a42c8ae8e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(path):\n",
    "    logging.info(f\"Extracting {path}\")\n",
    "    return spark.read.csv(path, header=True, inferSchema=True)\n",
    "\n",
    "sales = extract(\"/home/jovyan/work/data/sales.csv\")\n",
    "customers = extract(\"/home/jovyan/work/data/customers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab3c322-9c01-4e34-92be-ca2c35523f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+-------+--------+----------+\n",
      "|order_id|customer_id|order_date|product|quantity|unit_price|\n",
      "+--------+-----------+----------+-------+--------+----------+\n",
      "|       0|          0|         0|      0|       0|         0|\n",
      "+--------+-----------+----------+-------+--------+----------+\n",
      "\n",
      "+-----------+-------------+------+\n",
      "|customer_id|customer_name|region|\n",
      "+-----------+-------------+------+\n",
      "|          0|            0|     0|\n",
      "+-----------+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_missing_simple(df):\n",
    "    logging.info(\"Checking for missing/null values\")\n",
    "    \n",
    "    # Only check for NULL values (works for all data types)\n",
    "    return df.select([\n",
    "        count(when(col(c).isNull(), c)).alias(c) for c in df.columns\n",
    "    ])\n",
    "\n",
    "missing_sales = count_missing_simple(sales)\n",
    "missing_sales.show()\n",
    "\n",
    "missing_customers = count_missing_simple(customers)\n",
    "missing_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05121856-e4d5-4ca5-a7a5-bb22a8db8197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales columns: ['order_id', 'customer_id', 'order_date', 'product', 'quantity', 'unit_price']\n",
      "Customers columns: ['customer_id', 'customer_name', 'region']\n",
      "Duplicate sales: 0\n",
      "Duplicate customers: 0\n"
     ]
    }
   ],
   "source": [
    "def count_duplicates(df, key_cols):\n",
    "    logging.info(\"Checking duplicates\")\n",
    "    return df.count() - df.dropDuplicates(key_cols).count()\n",
    "\n",
    "# First, let's see what columns we actually have\n",
    "print(\"Sales columns:\", sales.columns)\n",
    "print(\"Customers columns:\", customers.columns)\n",
    "\n",
    "# Use the correct column names from your data\n",
    "dup_sales = count_duplicates(sales, [\"order_id\"])  # Changed from \"sale_id\" to \"order_id\"\n",
    "print(\"Duplicate sales:\", dup_sales)\n",
    "logging.info(f\"Duplicate sales: {dup_sales}\")\n",
    "\n",
    "dup_customers = count_duplicates(customers, [\"customer_id\"])\n",
    "print(\"Duplicate customers:\", dup_customers)\n",
    "logging.info(f\"Duplicate customers: {dup_customers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887261af-0ec8-4cc4-bec8-2338aba257c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  summary         unit_price\n",
      "0   count                 10\n",
      "1    mean             15.892\n",
      "2  stddev  9.498211293595112\n",
      "3     min                4.5\n",
      "4     max              29.99\n",
      "Warning: Could not compute quartiles for column unit_price.\n",
      "Outliers in unit_price: 0 (range: None–None)\n"
     ]
    }
   ],
   "source": [
    "def detect_outliers(df, colname):\n",
    "    logging.info(f\"Detecting outliers in {colname}\")\n",
    "    desc = df.select(colname).describe().toPandas()\n",
    "    print(desc)  # Debug print\n",
    "    # Check if 25% and 75% exist\n",
    "    if not (\"25%\" in desc['summary'].values and \"75%\" in desc['summary'].values):\n",
    "        print(f\"Warning: Could not compute quartiles for column {colname}.\")\n",
    "        logging.warning(f\"Could not compute quartiles for column {colname}.\")\n",
    "        return 0, None, None\n",
    "    try:\n",
    "        q1 = float(desc[desc['summary'] == '25%'][colname].values[0])\n",
    "        q3 = float(desc[desc['summary'] == '75%'][colname].values[0])\n",
    "        iqr = q3 - q1\n",
    "        lower, upper = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "        outlier_count = df.filter((col(colname) < lower) | (col(colname) > upper)).count()\n",
    "        return outlier_count, lower, upper\n",
    "    except Exception as e:\n",
    "        print(f\"Error during outlier calc: {e}\")\n",
    "        logging.warning(f\"Error during outlier calc for {colname}: {e}\")\n",
    "        return 0, None, None\n",
    "\n",
    "# Usage:\n",
    "if \"unit_price\" in sales.columns:\n",
    "    out_count, low, up = detect_outliers(sales, \"unit_price\")\n",
    "    print(f\"Outliers in unit_price: {out_count} (range: {low}–{up})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae0a99c-6561-460c-a7ac-1254d7abd661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "sales = sales.withColumn(\"unit_price\", col(\"unit_price\").cast(\"double\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
